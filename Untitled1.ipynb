{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "312827ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import numpy as np\n",
    "\n",
    "def run(num=0,text = \"school \",sentence_length=10):\n",
    "    if num==0:\n",
    "        max_len=322\n",
    "    else:\n",
    "        max_len=176\n",
    "    with open('dataset.txt','r') as file:\n",
    "        dataset=file.read()\n",
    "        file.close()\n",
    "    with open('tokenizer.pkl','rb') as tokenfil:\n",
    "        tokenizer=pickle.load(tokenfil)\n",
    "    model_without_preprocessing=load_model(\"next_word_pred_model.h5\")\n",
    "    model_with_preprocessing=load_model(\"next_word_pred_model_with_preprocessing.h5\")\n",
    "    print(model_with_preprocessing.summary())\n",
    "    if num==1:\n",
    "        model=model_with_preprocessing\n",
    "    else:\n",
    "        model=model_without_preprocessing\n",
    "    text=text.lower()\n",
    "    for i in range(sentence_length):\n",
    "        # tokenize\n",
    "        token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "        # padding\n",
    "        padded_token_text = pad_sequences([token_text], maxlen=max_len-1, padding='pre')\n",
    "        # predict\n",
    "        pos = np.argmax(model.predict(padded_token_text))\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == pos:\n",
    "                text = text + \" \" + word\n",
    "    else:\n",
    "\n",
    "        if num==1:\n",
    "            #Lemmatize each word in the sentence\n",
    "            lemmatized_sentence = [lemmatizer.lemmatize(word, pos=\"a\") for word in text]\n",
    "\n",
    "            # Join the lemmatized words back into a sentence\n",
    "            lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "            lemmatized_sentence=lemmatizer.lemmatize(text, pos=\"v\")\n",
    "            print(lemmatized_sentence)\n",
    "        else:\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93a8f0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 175, 100)          44600     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 175, 50)           30200     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 175, 50)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 175, 50)           20200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 175, 50)           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 446)               22746     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137,946\n",
      "Trainable params: 137,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "school  rancho rancho rancho rancho rancho rancho rancho rancho rancho rancho\n"
     ]
    }
   ],
   "source": [
    "run(num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8911905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320e2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
